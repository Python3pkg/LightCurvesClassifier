{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalation\n",
    "\n",
    "[run instal]\n",
    "...\n",
    "\n",
    "After the installation \"lcc\" command will be available from the commandline\n",
    "\n",
    "## Initializing project directory\n",
    "\n",
    "Run\n",
    "\n",
    "``` lcc create_project \"project_name\" \"rel_project_dir\" ```\n",
    "\n",
    "to create project directory with neccessary folders tree and the settings file. If \"project_name\" and \"rel_project_dir\" are not specified new project with default name \"project\" will be created in the current directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Curve Classifier\n",
    "\n",
    "## Introduction\n",
    "The Light Curve Classifier is a Python package for classifying astronomical objects. It is\n",
    "accomplished mainly by their light curves, but there are no limits to achieve that\n",
    "by any other attribute of stars. The package can used for several tasks:\n",
    "\n",
    "+ Download light curves from implemented databases\n",
    "+ Teach implemented filters on train sample in order to filter another stars\n",
    "+ Run systematic search and filter stars directly in databases\n",
    "\n",
    "New filters, database connectors or classifiers can be easily implemented thanks to class interfaces (see \"Implementing new classes\" section). However there are many of them already included, so there are lots of tasks which can be done just via command line. Package can be used in two ways:\n",
    "\n",
    "+ Via command line\n",
    "\n",
    "+ By using the package programatically \n",
    "\n",
    "The second option looks more complicated for the first sight, but the uppermost layer of modules which need to be used is quite simple. This approach allows to utilize the whole potential of the program. In the first part usage via command line will be introduced.\n",
    "\n",
    "## Data folders tree\n",
    "\n",
    "In order to create necessary data folders for input/output there is a script build data structure.py\n",
    "\n",
    "There is one mandatory key which have to be specified.\n",
    "There are example scripts in src/examples and example light curves in src/examples/ex-\n",
    "amples data. If build data structure.py is run with ’y’ option all example data is trans-\n",
    "ferred into data folders and all example scripts are executed. There is no need to store\n",
    "more data, because prepare scripts will create files for tuning and queries and tuning\n",
    "scripts make filters etc.\n",
    "In case of parameter ’y’ just empty data folders will be created.\n",
    "3\n",
    "\n",
    "## Command line \n",
    "\n",
    "These exutables are all you need for using the package:\n",
    "\n",
    "1. make filter.py\n",
    "2. filter stars.py\n",
    "3. prepare query.py\n",
    "\n",
    "#### Make filter\n",
    "This script creates new filter object which is then able to recognize if an inspected\n",
    "star object is a member of searched group or if it is not. The learning is performed\n",
    "by different methods (which can be specified) on train sample of searched objects and\n",
    "contamination objects (other stars).\n",
    "\n",
    "#### Filter stars\n",
    "After creation of filter object it is possible to filter given sample of star objects. In-\n",
    "spected stars can be obtained by various connectors which will be described in a next\n",
    "chapter.\n",
    "\n",
    "#### Prepare query\n",
    "Support tool for making files of queries or files of tuning combinations in given ranges.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Intro via example\n",
    "\n",
    "#### Filtering stars via Abbe Value Filter\n",
    "\n",
    "Our task is to find stars with a trend in their light curves. It can be reached by calculating of Abbe value.\n",
    "\n",
    "First of all we need to prepare files of filter parameters which will be tuned. For Abbe Value Filter there is just one parameter which have to be find - dimension of reduced light curve (bins). Let's try values between 10 and 150 which step of 5:\n",
    "\n",
    "```\n",
    "./prepare_query.py -o tuning_abbe_filter.txt  -p bins -r 10:150:5\n",
    "```\n",
    "\n",
    "This generates file named \"tuning_abbe_filter.txt\" in data/inputs.\n",
    "\n",
    "| #bins |\n",
    "|-------|\n",
    "| 10    |\n",
    "| 20    |\n",
    "| 30    |\n",
    "| ...   |\n",
    "| 130   |\n",
    "| 140   |\n",
    "\n",
    "\n",
    "Then we can learn AbbeValueFilter on train sample of quasars and non variable stars as contamination sample. Our learning method is GaussianNBDec (description of all implemented methods can be found in a next section).\n",
    "\n",
    "```\n",
    "./make_filter.py  -i tuning_abbe_filter.txt -f AbbeValueFilter -s quasars -c stars -d GaussianNBDec -o AbbeValue_quasar.filter -l AbbeValue_quasar\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "./filter_stars.py -d FileManager -i query_folders.txt -f AbbeValue_quasar.filter -o examples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database connectors\n",
    "## Usage\n",
    "\n",
    "\n",
    "There are two groups of database connectors:\n",
    "\n",
    "+ Star catalogs\n",
    "    - Information about star attributes can be obtained\n",
    "\n",
    "+ Light curves archives\n",
    "    - Information about star attributes can be obtained and its light curves\n",
    "    \n",
    "In term of program structure - all connectors return stars objects, but just Light curves archives also obtaining light curves. Star objects can be obtained by common way:\n",
    "\n",
    "    queries = [{\"ra\": 297.8399, \"dec\": 46.57427, \"delta\": 10},\n",
    "                {\"kic_num\": 9787239},\n",
    "                {\"kic_jkcolor\": (0.3, 0.4), \"max_records\": 5}]\n",
    "    client = StarsProvider().getProvider(obtain_method=\"KeplerArchive\",\n",
    "                                         obtain_params=queries)\n",
    "    stars = client.getStarsWithCurves()\n",
    "\n",
    "Because of common API for all connectors therefore databases can be queried by the syntax. Keys for quering depends on designation in particular databases. Anyway there are common keys for cone search:\n",
    "\n",
    "* ra\n",
    "    - Right Ascension in degrees\n",
    "    \n",
    "* dec\n",
    "    - Declination in degrees\n",
    "    \n",
    "* delta\n",
    "    - Circle radius in arcseconds\n",
    "    \n",
    "* nearest (optional)\n",
    "    - Nearest star to the seach center is returned if it is True\n",
    "    \n",
    "    \n",
    "Stars can be then easily crossmatched:\n",
    "\n",
    "    queries = [{\"ra\": 0.4797, \"dec\": -67.1290, \"delta\": 10, \"nearest\": True}]\n",
    "    \n",
    "    one_star_in_many_databases = []\n",
    "    for archive in [\"AsasArchive\", \"OgleII\", \"CorotBrightArchive\", \"KeplerArchive\"] :\n",
    "        client = StarsProvider().getProvider(obtain_method=archive,\n",
    "                                             obtain_params=queries)\n",
    "        one_star_in_many_databases += client.getStarsWithCurves()\n",
    "\n",
    "## Implementing new connectors\n",
    "\n",
    "All connectors accept input (queries) in unitary format (list of dictionaries) and implements one (stars catalogs) or two (light curves archives) methods which return Star object. In order to access the connector by *StarsProvder* (as is shown in examples above) the module have to be located in *db_tier.connectors* package. This is all magic need to be done to have compatible connector with rest of the package.\n",
    "\n",
    "The connectors have to inherit *StarsCatalogue* or *LightCurvesDb* classes. This ensures that all connectors are able to return unitary Star objects in the same manner. Inheritage of these classes helps *StarsProvider* to find connectors.\n",
    "\n",
    "Moreover connectors can inherite other interface classes which bring more funcionality to child classes. For example *TapClient* can be used for VO archives providing TAP access. \n",
    "\n",
    "### VizierTapBase\n",
    "\n",
    "Common interface for all databases accessible via Vizier. For many databases there is no need to write any new methods. Let's look at an example of implementation of MACHO database:\n",
    "\n",
    "    class MachoDb(VizierTapBase, LightCurvesDb):\n",
    "        '''\n",
    "        Client for MACHO database\n",
    "\n",
    "        EXAMPLES:\n",
    "        ---------\n",
    "            queries = [{\"Field\": 1 , \"Tile\": 3441, \"Seqn\": 25}]\n",
    "            client = StarsProvider().getProvider(obtain_method=\"MachoDb\",\n",
    "                                                 obtain_params=queries)\n",
    "            stars = client.getStarsWithCurves()\n",
    "        '''\n",
    "\n",
    "        TABLE = \"II/247/machovar\"\n",
    "        LC_URL = \"http://cdsarc.u-strasbg.fr/viz-bin/nph-Plot/w/Vgraph/txt?II%2f247%2f.%2f{macho_name}&F=b%2br&P={period}&-x&0&1&-y&-&-&-&--bitmap-size&600x400\"\n",
    "\n",
    "        NAME = \"{Field}.{Tile}.{Seqn}\"\n",
    "        LC_FILE = \"\"\n",
    "\n",
    "        LC_META = {\"xlabel\": \"Time\",\n",
    "                   \"xlabel_unit\": \"MJD (JD-2400000.5)\",\n",
    "                   \"origin\": \"MACHO\"}\n",
    "\n",
    "        IDENT_MAP = {\"MachoDb\":  (\"Field\", \"Tile\", \"Seqn\")}\n",
    "        MORE_MAP = collections.OrderedDict(((\"Class\", \"var_type\"),\n",
    "                                            (\"Vmag\", \"v_mag\"),\n",
    "                                            (\"Rmag\", \"r_mag\"),\n",
    "                                            (\"rPer\", \"period_r\"),\n",
    "                                        (\"bPer\", \"period_b\")))\n",
    "\n",
    "    \n",
    "## Available connectors\n",
    "### KeplerArchive\n",
    "Connector to Kepler Input Catalog Targets by [kplr](http://dan.iel.fm/kplr/) package. See available query keys in [official field description](http://archive.stsci.edu/search_fields.php?mission=kic10). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "How does it work?\n",
    "The package is quite extensive and capable to be extended by user classes (see Pro-\n",
    "gramers guide for more information). However, the upper most layer for users usage is\n",
    "quite simple and straightforward. Whole procedure of finding the most optional filter\n",
    "parameters and then sorting stars can be executed by two commands e.g.:\n",
    "m a k e f i l t e r . py − i f i l t e r c o m b i n a t i o n s . t x t −f C o m p a r i n g F i l t e r −s q u a s a r s\n",
    "−c c e p h e i d s −d NeuronDecider −o M y F i l t e r . p i c k l e\n",
    "f i l t e r s t a r s . py − i o g l e q u e r y . t x t −o o g l e l c s −d ” O g l e I I ” −f M y F i l t e r .\n",
    "pickle\n",
    "All combinations for evaluating are located in ’filter combinations.txt’, ’ComparingFil-\n",
    "ter’ is used, searched stars are quasars and there is a sample of cepheids in order to\n",
    "train the ’NeuronDecider’ and the most optional filter is saved as ’MyFilter.pickle’.\n",
    "This filter is then used for filtering ’OgleII’ database via queries in ’ogle query.txt’ and\n",
    "the result file with light curves are saved into ’ogle lcs’ folder.\n",
    "3.1\n",
    "Status file\n",
    "Parameters to try or queries can be specified in a special file where first row starts with\n",
    "’#’ and then there are names of parameters which can be used for finding the most\n",
    "optional parameters of a filter or as query for a database. Next rows consist of values\n",
    "for tuning or queries. All columns are separated by ’;’ (can be changed in settings).\n",
    "Example status files used as input\n",
    "#s t a r i d ; t a r g e t ; f i e l d n u m\n",
    "5 ; lmc ; 1\n",
    "7 ; smc ; 1\n",
    "7 5 ; lmc ; 2\n",
    "23.2 Data folder hierarchy\n",
    "3 HOW DOES IT WORK?\n",
    "1 ; smc ; 2\n",
    "Listing 1: Query Ogle database\n",
    "#d a y s p e r b i n\n",
    "0.5\n",
    "10\n",
    "30\n",
    "50\n",
    "Listing 2: Tune AbbeValueFilter according to given combination of parameters\n",
    "Example output status files:\n",
    "#vario days per bin vario alphabet size false negative rate\n",
    "9\n",
    "17\n",
    "0.0\n",
    "8\n",
    "16\n",
    "0.0\n",
    "false positive rate true negative rate precision true positive rate\n",
    "0.2\n",
    "0.8\n",
    "0.83\n",
    "1.0\n",
    "0.2\n",
    "0.8\n",
    "0.83\n",
    "1.0\n",
    "Table 1: Combinations for tuning and result statistical values\n",
    "#s t a r i d ; f i e l d n u m ; t a r g e t ; name ; found ; f i l t e r e d ; p a s s e d\n",
    "1 ; 1 ; lmc ; LMC SC1 1 ; True ; True ; F a l s e\n",
    "2 ; 1 ; lmc ; LMC SC1 2 ; True ; True ; F a l s e\n",
    "3 ; 1 ; lmc ; LMC SC1 3 ; True ; True ; F a l s e\n",
    "4 ; 1 ; lmc ; LMC SC1 4 ; True ; True ; F a l s e\n",
    "5 ; 1 ; lmc ; LMC SC1 5 ; True ; F a l s e ; F a l s e\n",
    "6 ; 1 ; lmc ; LMC SC1 6 ; True ; True ; F a l s e\n",
    "7 ; 1 ; lmc ; LMC SC1 7 ; True ; True ; F a l s e\n",
    "8 ; 1 ; lmc ; LMC SC1 8 ; True ; True ; F a l s e\n",
    "9 ; 1 ; lmc ; LMC SC1 9 ; True ; True ; F a l s e\n",
    "Listing 3: Queries and result of filtering\n",
    "3.2\n",
    "Data folder hierarchy\n",
    "Next to the src/ (source) folder there is a data/ folder where all data files are saved.\n",
    "All input/outputs are loaded/saved into a folder in data/.\n",
    "This behavior can be suppressed by entering word ’HERE:’ (e.g. ’HERE:file name’). It\n",
    "forces to take relative path from the directory of executing the script.\n",
    "There are 5 main folders:\n",
    "1. data/inputs/\n",
    "• Location of files of queries and files from tuning parameters\n",
    "2. data/light curves/\n",
    "• Location of light curve subfolders.\n",
    "3. data/star filters/\n",
    "33.3 Getting stars\n",
    "3 HOW DOES IT WORK?\n",
    "• Location where tuned filters are saved and can be loaded by make filer.py\n",
    "script\n",
    "4. data/tuning logs/\n",
    "• Location of output files from tuning - statistic for every combination of pa-\n",
    "rameters, graphs (probability distribution with train objects and histograms).\n",
    "5. data/databases/\n",
    "• Location of local db files (e.g. sqlite db files).\n",
    "3.3\n",
    "Getting stars\n",
    "For filtering\n",
    "Stars for filtering can be obtained by providing database key and name of query file\n",
    "separated by ”:”.\n",
    "• db name : query f ile.\n",
    "Database key is resolved as name of connector class (Any class in src/db tier/connectors/\n",
    "which inherits StarsCatalogue base class) and query f ile is name of the file with queries\n",
    "in data/inputs/.\n",
    "#s t a r i d ; t a r g e t ; f i e l d n u m\n",
    "5 ; lmc ; 1\n",
    "5 ; smc ; 1\n",
    "5 ; smc ; 2\n",
    "8 ; lmc ; 1\n",
    "Listing 4: Example query file for Ogle database\n",
    "For tuning filters\n",
    "There are some special approaches to obtain stars for tuning filters. The approach\n",
    "mentioned above for filtering is accessible by almost the same way, but with adding key\n",
    "”QUERY” as is shown below.\n",
    "1. QUERY:db name : query f ile\n",
    "- Remote database is queried (db key is name of connector class)\n",
    "Example: QUERY:OgleII:query file.txt\n",
    "2. LOCAL:db name : query f ile\n",
    "- Local database is queried (according to key in settings.DATABASES)\n",
    "Example: LOCAL:milliquas:query file.txt\n",
    "43.4 Deciders\n",
    "4 WHAT CAN BE USED?\n",
    "3. stars f older key : number or stars f older key%f loat number or stars f older key\n",
    "- Light curves from folder according to first key is loaded (according to settings.STARS PATH\n",
    "dictionary). All stars are obtained if there is no special mark with number, in\n",
    "case of integer after ’:’ just this number of stars are loaded and if there are is a\n",
    "float number after ’%’ this percentage number of all stars are loaded.\n",
    "Example: quasars:10 or be stars%0.5 or cepheids\n",
    "The behavior of last two approaches is possible via first method. Local database db key\n",
    "(connector class name) is LocalDbClient and then it is necessary to add column named\n",
    "db key into query file to resolve which local database will be queried. Light curves in\n",
    "folders can be accessed by F ileM anager and including path column (optionally with\n",
    "f iles limit column).\n",
    "#r mag ; b mag ; s t a r c l a s s ; r e d s h i f t\n",
    ">1; >1;Q;>5\n",
    "Listing 5: Query file for LOCAL:db name : query f ile\n",
    "Please note that using special symbols ”>”, ”<” an ”! =” is possible just for local\n",
    "database queries so far. This will be upgraded in a next version.\n",
    "3.4\n",
    "Deciders\n",
    "Deciders manage all learning and then recognizing of inspected objects. They can\n",
    "be loaded via name of their class (if they are located in src/stars processing/deciders\n",
    "inheriting BaseDesider class). They are learned on train sample of searched and con-\n",
    "tamination objects. After learning there are tuning log file which evaluate precision of\n",
    "the filtering. Also there are histograms for every free variable and probability space\n",
    "plot if there is two free variables.\n",
    "In current version, parameters of filters are evaluated according to precision defined\n",
    "true positive\n",
    ". The combination with highest precision is considered as the\n",
    "as true positive+f\n",
    "alse p ositive\n",
    "best. It can be changed in cong/deciders settings.\n",
    "4\n",
    "What can be used?\n",
    "There are many modules ready to use - filters, connectors and deciders. In this chapter\n",
    "they will be briefly introduced.\n",
    "4.1\n",
    "Filters\n",
    "ColorIndexFilter\n",
    "ColorIndexFilter sorts stars according to magnitudes in different filters. It is necessary\n",
    "to specify colors for a filter as python list and particular colors surrounded by commas\n",
    "as is shown in 6. Ranges of colors are learned by a decider.\n",
    "54.1 Filters\n",
    "4 WHAT CAN BE USED?\n",
    "#c o l o r s\n",
    "[ ” b mag−r mag ” ]\n",
    "[ ” v mag ” , ” i mag ” ]\n",
    "[ ” b mag−r mag ” , ”v mag−i mag ” ]\n",
    "Listing 6: File of combinations for tuning\n",
    "AbbeValueFilter\n",
    "Abbe value quantify extensions of trends in light curves and it is defined as:\n",
    "n\n",
    "A =\n",
    "n − 1\n",
    "n−1\n",
    "2\n",
    "μ=1 (x μ+1 − x μ )\n",
    "n\n",
    " ̄ ) 2 ,\n",
    "μ=1 (x μ − x\n",
    ".\n",
    "(1)\n",
    "The parameter which needs to be calculated is days per bin which is ratio for dimension\n",
    "transfer. Inner variable which is calculated by learning is Abbe value limit of searched\n",
    "objects and contamination objects.\n",
    "ComparingFilter\n",
    "The filter compare two light curves of stars and measure dissimilarity of them by SAX\n",
    "method (see https://cs.gmu.edu/ jessica/sax.htm). Methods for comparing light curves\n",
    "are described by sub-filters. There are three implemented sub-filters:\n",
    "• CurvesShapeFilter - compares shapes of light curves\n",
    "• HistShapeFilter - Compares shapes of light curve’s histograms\n",
    "• VariogramShapeFilter - Compare shapes of light curve’s variograms\n",
    "Given sample of searched objects is split into a train sample and a reference sample\n",
    "which is then compared with inspected light curves. There are coordinates (one co-\n",
    "ordinate per sub-filter) calculated for every inspected star as average distance to all\n",
    "reference stars (comparing stars). See 6.1.\n",
    "During tuning filters there is no need to specify all subfilters , but just ComparingFilter\n",
    "and subfilters are resolved automatically by parameters specified in the file of filter\n",
    "combinations (see 6.1)\n",
    "VariogramSlope\n",
    "It filters stars according to variogram slopes of their light curves.\n",
    "CurveDensityFilter\n",
    "It filters stars with lower density of measurement per day then it is desired. For example\n",
    "it can filter all stars with light curves where is no more measurement then 50 per day\n",
    "etc.\n",
    "64.2 Implemented connectors\n",
    "4.2\n",
    "4 WHAT CAN BE USED?\n",
    "Implemented connectors\n",
    "OgleII BVI database\n",
    "This module is connected on query webpage at http://ogledb.astrouw.edu.pl/ ogle/photdb/bvi query.html.\n",
    "Database can be queried by one of these combinations\n",
    "• ra, dec, target\n",
    "• f ield, starid, target\n",
    "• f ield num, starid, target\n",
    "Both right ascension and declination are in angle degrees, target is lmc for Large Magel-\n",
    "lanic Cloud, smc for Small Magellanic Cloud and bul for galactic bulge. Each observed\n",
    "target is divided into f ields - LM C SC1, SM C SC1 and BU L SC1 are first fields\n",
    "in these target areas. Anyway it is recommended to use f ield num so the root name\n",
    "is resolved according to target. Query f ield:LM C SC11, starid:5, target:lmc is the\n",
    "same as f ield num:11, starid:5, target:lmc.\n",
    "Stars obtained from this database contain a light curve in I filter and length of approx-\n",
    "imately 2000 days, coordinates and magnitudes in B, V and I filter.\n",
    "LocalDbClient\n",
    "This connector manages local databases. They are accessible via db key parameter. All\n",
    "stars downloaded during filtering are uploaded into local database with a reference to\n",
    "a folder and name of light curve file.\n",
    "Also there is a Milliquas database (included as SQLite file) of 1.4 millions of quasars.\n",
    "See http://heasarc.gsfc.nasa.gov/w3browse/all/milliquas.html. The database scheme is\n",
    "the same as for database for saving downloaded stars.\n",
    "74.2 Implemented connectors\n",
    "Key\n",
    "id\n",
    "name\n",
    "identifier\n",
    "db origin\n",
    "ra\n",
    "dec\n",
    "star class\n",
    "light curve\n",
    "uploaded\n",
    "b mag\n",
    "v mag\n",
    "i mag\n",
    "r mag\n",
    "redshift\n",
    "lc n\n",
    "lc time delta\n",
    "crossmatch id\n",
    "Type\n",
    "int\n",
    "str\n",
    "str\n",
    "str\n",
    "float\n",
    "float\n",
    "str\n",
    "str\n",
    "datetime\n",
    "float\n",
    "float\n",
    "float\n",
    "float\n",
    "float\n",
    "int\n",
    "float\n",
    "ints (one to many)\n",
    "4 WHAT CAN BE USED?\n",
    "Description\n",
    "Database identifier\n",
    "Name of the star\n",
    "Identifier in the database db origin\n",
    "Name of database from which it was downloaded\n",
    "Right ascension on degreees\n",
    "Declination in degrees\n",
    "Name of type of the star\n",
    "Name of light curve file and path from data/light curves\n",
    "Date of uploading\n",
    "Magnitude in B filter in mag\n",
    "Magnitudein V filter in mag\n",
    "Magnitude in I filter in mag\n",
    "Magnitude in R filter in mag\n",
    "Redshift value\n",
    "Number of point of light curve\n",
    "Time length of observing in light curve\n",
    "Database identifier to crossmatched stars\n",
    "Table 2: Database scheme for local and milliquas database\n",
    "Database can be queried via keys in 2. It also supports >, < and ! = operators (as was\n",
    "shown in 5). Star objects returned by queries also contain light curves, so it is possible\n",
    "to filter them by light curve filters or just show their plots.\n",
    "#r mag ; b mag ; db key\n",
    ">1; >1; l o c a l\n",
    "Listing 7: Query file for local database\n",
    "#r mag ; b mag ; db key\n",
    ">1; >1; m i l l i q u a s\n",
    "Listing 8: Query file for milliquas database\n",
    "Please note that there cannot be present two or more keys with one name in one query\n",
    "(same row), so it is not possible to have close ranges of values so far. For example\n",
    "dec > 20.4; dec < 20.5. This will be fixed in a next version.\n",
    "KeplerArchive\n",
    "Connector to Kepler Objects of Interest catalog [1] and its light curves from MAST [?].\n",
    "The kplr package [?] was used for this purpose. There are two options for query so far:\n",
    "1. By Kepler unique identifier - kic\n",
    "2. By coordinates with square radius for area search\n",
    "84.3 Deciders\n",
    "5 USAGE\n",
    "FileManager\n",
    "This connector class manages light curve files. Path is resolved via settings.ST ARS P AT H\n",
    "variable where key is the key which is mentioned in queries and value is real path. So it is\n",
    "possible to load stars from any local folder in case if it is registered in settings.ST ARS P AT H.\n",
    "However stars folders can be accessed even by specifying relative paths if path variable\n",
    "starts with ”Here:”.\n",
    "Please note that queried folder cannot contains other files with same suffix as light\n",
    "curves - basically all file with suffix dat is considered as light curves. It can be changed\n",
    "by suffix variable in the query file.\n",
    "4.3\n",
    "Deciders\n",
    "Learned deciders estimate probability of membership of inspected objects to the searched\n",
    "group. By default border value is set to 0.85 - every object with probability of member-\n",
    "ship higher then 85% is considered as a member of searched group. It can be changed\n",
    "in src/conf/deciders settings.py.\n",
    "NeuronDecider\n",
    "It learns neuron grid according to Pybrain implementation. By default there is one\n",
    "hidden layer. It can be changed in src/conf/deciders settings.py. Number of input\n",
    "neurons is flexible and it is automatically set according to number of free variables of\n",
    "given filter. For more information see: pybrain.org\n",
    "LDADec\n",
    "See http://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html\n",
    "GaussianNBDec\n",
    "See http://scikit-learn.org/stable/modules/naive bayes.html#gaussian-naive-bayes\n",
    "GMMBayesDec\n",
    "See http://scikit-learn.org/stable/modules/naive bayes.html\n",
    "QDADec\n",
    "See http://scikit-learn.org/0.16/modules/generated/sklearn.qda.QDA.html\n",
    "5\n",
    "Usage\n",
    "The brief description of program parameters can be shown by running with -h.\n",
    "95 USAGE\n",
    "Parameters for make filter.py\n",
    "-i, –input\n",
    "Name (with path if desired) to the file of filter parameters combinations in data/inputs/.\n",
    "For relative path from folder of executing the script enter ”HERE:” before the path.\n",
    "-o, –file name\n",
    "Name of result filter file\n",
    "-f, –filter\n",
    "Name of filter (class) name in src/stars processing/filters imp/. More filters can be used\n",
    "by adding more ”-f filter name” pairs. Run script without parameters to see available\n",
    "filters.\n",
    "-s, –searched\n",
    "Special text for obtaining sample of searched stars. See 3.3 for more information.\n",
    "-c, –contamination\n",
    "Special text for obtaining sample of contamination stars. See 3.3 for more information.\n",
    "-d, –decider\n",
    "Decider (class) name in src/stars processing/deciders/. Run script without parameters\n",
    "to see available deciders.\n",
    "-l, –log\n",
    "Name of the folder where log files about tuning and plots will be saved in data/tun-\n",
    "ing logs/. For relative path from folder of executing the script enter ”HERE:” before\n",
    "the path.\n",
    "Parameters for filter stars.py\n",
    "-o, –output\n",
    "Name of folder for saving light curves of stars passed thru filtering from data/light curves/.\n",
    "For relative path from folder of executing the script enter ”HERE:” before the path.\n",
    "-i, –input\n",
    "Name of the file of queries in data/inputs/. For relative path from folder of executing\n",
    "the script enter ”HERE:” before the path.\n",
    "105.1 Parameters for prepare query.py\n",
    "6 EXAMPLES\n",
    "-d, –database\n",
    "Name of database connector (name of the class in src/db tier/connectors/). Run script\n",
    "without parameters to see available connectors.\n",
    "-f, –filter\n",
    "Name of the filter file in data/star filters/. More filters can be used by adding more ”-f\n",
    "filter name” pairs.\n",
    "5.1\n",
    "Parameters for prepare query.py\n",
    "-o, –output\n",
    "Name of the query file or file of filter combinations which will be created in data/inputs\n",
    "-p, –param\n",
    "Parameter name (column header) which will be generated\n",
    "-r, –range\n",
    "Range of parameters separated by ’:’ - from num:to num:step num.\n",
    "-d, –delim\n",
    "Delimiter for the output file\n",
    "NOTE: There have to be the same number of –param an –range parameters\n",
    "6\n",
    "6.1\n",
    "Examples\n",
    "Classifying quasars in histogram-variogram space\n",
    "Prepare files\n",
    "First of all we need to create a file of parameters from which the best combination will\n",
    "be used for creating the filter.\n",
    "p r e p a r e q u e r y . py −o examples / t u n i n g h i s t v a r i o f i l t e r . t x t −p\n",
    "h i s t d a y s p e r b i n −r ” 9 7 ; 8 0 ” −p v a r i o d a y s p e r b i n −r 9 −p\n",
    "v a r i o a l p h a b e t s i z e −r 16 −p h i s t a l p h a b e t s i z e −r 7\n",
    "Listing 9: Creating of the file o filter parameters\n",
    "File of two combination tuning histvario filter.txt is created in data/inputs/examples/.\n",
    "Also we can make query file for the filtering.\n",
    "116.1 Classifying quasars in histogram-variogram space\n",
    "6 EXAMPLES\n",
    "p r e p a r e q u e r y . py −o examples / q u e r y o g l e . t x t −p s t a r i d −r 1 : 1 0 −p t a r g e t −\n",
    "r lmc −p f i e l d n u m −r 1\n",
    "Listing 10: Query file for OgleII database\n",
    "Make filter\n",
    "Now we can make the filter. In this step it is convenient to check deciders settings\n",
    "file (src/conf/deciders settings.py) and think about T RESHOLD parameter. During\n",
    "filtering all inspected stars are evaluated by probability of membership. All stars with\n",
    "higher probability then T RESHOLD will pass thru filtering.\n",
    "m a k e f i l t e r . py − i examples / t u n i n g h i s t v a r i o f i l t e r . t x t −f\n",
    "C o m p a r i n g F i l t e r −s q u a s a r s : 2 0 −c c e p h e i d s : 5 −c s t a r s : 1 5 −d\n",
    "GaussianNBDec −o examples / H i s t V a r i o q u a s a r s . f i l t e r − l examples /\n",
    "HistVario quasars\n",
    "Listing 11: Creating of the filter\n",
    "We are training the filter to find quasars and distinguish them from non variable stars\n",
    "and cepheids.\n",
    "Tuning i s about t o s t a r t . There a r e 2 c o m b i n a t i o n s t o t r y\n",
    "Estimating combinations :\n",
    "[############################################################] 2/2\n",
    "∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗\n",
    "Best params :\n",
    "{\n",
    "” vario days per bin ”: 9 ,\n",
    "” hist alphabet size ”: 7 ,\n",
    "” h i s t d a y s p e r b i n ” : 97 ,\n",
    "” v a r i o a l p h a b e t s i z e ” : 16\n",
    "}\n",
    "Statistic :\n",
    "{\n",
    "” precision ”: 1.0 ,\n",
    "” true positive rate ”: 0.833 ,\n",
    "” true negative rate ”: 1.0 ,\n",
    "” f als e po sit ive ra te ”: 0.0 ,\n",
    "” f a l s e n e g a t i v e r a t e ”: 0.059\n",
    "}\n",
    "Listing 12: Commandline output\n",
    "Information about tuning is saved into data/tuning logs to examples/HistVario quasars\n",
    "(specified in 11 by ’-f’). There are one log file about precision of given combinations.\n",
    "#v a r i o d a y s p e r b i n\n",
    "vario alphabet size\n",
    "true negative rate\n",
    "9\n",
    "7\n",
    "97\n",
    "hist alphabet size\n",
    "hist days per bin\n",
    "precision\n",
    "true positive rate\n",
    "false positive rate\n",
    "false negative rate\n",
    "16\n",
    "1.0\n",
    "0.833\n",
    "1.0\n",
    "0.0\n",
    "0.059\n",
    "126.1 Classifying quasars in histogram-variogram space\n",
    "9\n",
    "7\n",
    "80\n",
    "16\n",
    "1.0\n",
    "0.833\n",
    "6 EXAMPLES\n",
    "1.0\n",
    "0.0\n",
    "0.059\n",
    "Listing 13: HistVario quasars log.dat\n",
    "Also there are probability space image for every combination and histograms for every\n",
    "combination and every inner variable - in this example inner variable is dissimilarity in\n",
    "each subfilter.\n",
    "13REFERENCES\n",
    "REFERENCES\n",
    "Filter stars in OgleII\n",
    "Finally we can use our filter saved into data/star filters.\n",
    "f i l t e r s t a r s . py − i examples / q u e r y o g l e . t x t −o examples / −d ” O g l e I I ” −f\n",
    "examples / H i s t V a r i o q u a s a r s . f i l t e r\n",
    "Listing 14: Run filtering in OgleII\n",
    "Light curves of stars passed thru filtering are save into data/light curves + our output\n",
    "directory specified by ’-o’. Status file is also created in the folder.\n",
    "#s t a r i d ; f i e l d n u m ; t a r g e t ; name ; found ; f i l t e r e d ; p a s s e d\n",
    "1 ; 1 ; lmc ; LMC SC1 1 ; True ; True ; F a l s e\n",
    "2 ; 1 ; lmc ; LMC SC1 2 ; True ; True ; F a l s e\n",
    "3 ; 1 ; lmc ; LMC SC1 3 ; True ; True ; F a l s e\n",
    "4 ; 1 ; lmc ; LMC SC1 4 ; True ; True ; F a l s e\n",
    "5 ; 1 ; lmc ; LMC SC1 5 ; True ; True ; True\n",
    "6 ; 1 ; lmc ; LMC SC1 6 ; True ; True ; F a l s e\n",
    "7 ; 1 ; lmc ; LMC SC1 7 ; True ; True ; F a l s e\n",
    "8 ; 1 ; lmc ; LMC SC1 8 ; True ; True ; F a l s e\n",
    "9 ; 1 ; lmc ; LMC SC1 9 ; True ; True ; F a l s e\n",
    "Listing 15: Status file\n",
    "Stars passed thru filtering are also uploaded into local database and can be obtained\n",
    "again.\n",
    "References\n",
    "[1] “Nasa exoplanet archive.” http://exoplanetarchive.ipac.caltech.edu/.\n",
    "14\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
